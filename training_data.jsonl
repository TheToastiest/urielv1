{"norm_input":"Gaussian convolution smooths high-frequency noise in images.","selected_mem_text":"A Gaussian kernel attenuates high spatial frequencies, acting as a low-pass filter.","salience":[0.82,0.41,0.33,0.60],"route":1,"cav":[0.12,0.21,0.31,0.18,0.22,0.09,0.41,0.28,0.35,0.14,0.27]}
{"norm_input":"The central limit theorem states sums of iid variables tend to normality.","selected_mem_text":"Under finite variance, normalized sums converge in distribution to a Gaussian.","salience":[0.90,0.36,0.28,0.55],"route":1,"cav":[0.30,0.26,0.22,0.11,0.44,0.19,0.33,0.20,0.25,0.21,0.18]}
{"norm_input":"Fourier transform of a Gaussian is another Gaussian.","selected_mem_text":"The transform width is inversely proportional to the original standard deviation.","salience":[0.88,0.39,0.31,0.62],"route":1,"cav":[0.22,0.24,0.37,0.16,0.28,0.10,0.39,0.27,0.36,0.18,0.20]}
{"norm_input":"Stochastic gradient descent converges under diminishing step sizes.","selected_mem_text":"With convex objectives and Robbins Monro conditions, SGD converges almost surely.","salience":[0.74,0.45,0.29,0.52],"route":1,"cav":[0.19,0.29,0.32,0.15,0.25,0.11,0.31,0.22,0.34,0.17,0.23]}
{"norm_input":"Cross entropy measures the gap between predicted and true distributions.","selected_mem_text":"Minimizing cross entropy is equivalent to maximizing likelihood for categorical data.","salience":[0.70,0.44,0.26,0.50],"route":1,"cav":[0.21,0.20,0.30,0.13,0.27,0.12,0.29,0.24,0.31,0.16,0.22]}
{"norm_input":"Regularization controls overfitting by penalizing model complexity.","selected_mem_text":"L2 shrinkage biases weights toward zero and reduces variance.","salience":[0.65,0.40,0.25,0.49],"route":1,"cav":[0.18,0.22,0.28,0.12,0.24,0.10,0.26,0.20,0.29,0.14,0.19]}
{"norm_input":"Precision at k evaluates retrieval relevance among top results.","selected_mem_text":"P at 10 counts relevant documents in the first ten positions, divided by ten.","salience":[0.78,0.42,0.27,0.56],"route":1,"cav":[0.20,0.23,0.31,0.14,0.26,0.11,0.30,0.21,0.33,0.15,0.21]}
{"norm_input":"Macro F1 averages per class F1 regardless of frequency.","selected_mem_text":"It treats each class equally, useful with imbalance.","salience":[0.73,0.38,0.24,0.47],"route":1,"cav":[0.17,0.19,0.27,0.11,0.22,0.09,0.25,0.19,0.28,0.13,0.18]}
{"norm_input":"HNSW graphs enable fast approximate nearest neighbor search.","selected_mem_text":"Hierarchical layers reduce search while preserving recall with efSearch tuning.","salience":[0.80,0.46,0.33,0.58],"route":1,"cav":[0.24,0.27,0.34,0.16,0.29,0.12,0.35,0.26,0.37,0.18,0.23]}
{"norm_input":"Information retrieval benefits from hard negatives during training.","selected_mem_text":"In batch negatives improve discrimination by contrasting near but wrong items.","salience":[0.77,0.43,0.32,0.54],"route":1,"cav":[0.23,0.25,0.33,0.15,0.28,0.12,0.32,0.24,0.36,0.17,0.22]}
{"norm_input":"Transformers use attention to mix token interactions efficiently.","selected_mem_text":"Self attention computes weighted sums using query key similarity.","salience":[0.76,0.41,0.30,0.53],"route":1,"cav":[0.22,0.24,0.32,0.14,0.27,0.11,0.31,0.23,0.34,0.16,0.21]}
{"norm_input":"Dropout randomly masks activations to reduce co adaptation.","selected_mem_text":"At inference, scale weights to match expected activations.","salience":[0.66,0.35,0.24,0.44],"route":1,"cav":[0.16,0.18,0.26,0.10,0.21,0.08,0.24,0.18,0.27,0.12,0.17]}
{"norm_input":"Batch normalization stabilizes gradients by normalizing feature stats.","selected_mem_text":"It learns affine parameters to restore representation power.","salience":[0.69,0.36,0.26,0.46],"route":1,"cav":[0.17,0.19,0.27,0.11,0.22,0.09,0.25,0.19,0.28,0.13,0.18]}
{"norm_input":"Recall improves with larger candidate sets but increases latency.","selected_mem_text":"efSearch trades query time for accuracy in HNSW.","salience":[0.71,0.39,0.29,0.51],"route":1,"cav":[0.19,0.22,0.30,0.13,0.24,0.10,0.28,0.21,0.31,0.15,0.20]}
{"norm_input":"Temporal decay reduces the influence of stale memories.","selected_mem_text":"Exponential decay weights recent events more during retrieval.","salience":[0.72,0.40,0.28,0.50],"route":2,"cav":[0.18,0.23,0.29,0.12,0.25,0.10,0.27,0.22,0.30,0.14,0.19]}
{"norm_input":"Active learning queries uncertain samples to label.","selected_mem_text":"Entropy and margin criteria pick informative points.","salience":[0.64,0.37,0.25,0.45],"route":2,"cav":[0.17,0.20,0.26,0.11,0.22,0.09,0.24,0.20,0.27,0.13,0.18]}
{"norm_input":"Evaluation should report p50 and p95 latency with warm caches.","selected_mem_text":"Tail latency matters for user perception in interactive systems.","salience":[0.68,0.41,0.27,0.52],"route":3,"cav":[0.21,0.23,0.28,0.12,0.24,0.09,0.26,0.22,0.29,0.14,0.19]}
{"norm_input":"A B testing requires guardrails on bad outcomes.","selected_mem_text":"Promote only if quality improves and errors do not increase.","salience":[0.67,0.38,0.26,0.49],"route":3,"cav":[0.20,0.22,0.27,0.11,0.23,0.09,0.25,0.21,0.28,0.13,0.18]}
{"norm_input":"ONNX export captures the computation graph and parameters.","selected_mem_text":"Inference engines like ORT execute the exported graph efficiently.","salience":[0.74,0.42,0.30,0.55],"route":2,"cav":[0.22,0.24,0.30,0.13,0.26,0.11,0.29,0.23,0.31,0.15,0.20]}
{"norm_input":"Vector normalization to unit length improves cosine similarity stability.","selected_mem_text":"L2 normalization prevents magnitude from dominating dot products.","salience":[0.75,0.40,0.31,0.56],"route":2,"cav":[0.23,0.25,0.31,0.14,0.27,0.11,0.30,0.24,0.33,0.16,0.21]}
{"norm_input":"fn main() { println!(\"hello world\"); }","selected_mem_text":"Rust prints a line with println macro and a format string.","salience":[0.58,0.34,0.22,0.40],"route":0,"cav":[0.12,0.16,0.20,0.09,0.18,0.07,0.19,0.14,0.21,0.10,0.15]}
{"norm_input":"pub fn add(a: i32, b: i32) -> i32 { a + b }","selected_mem_text":"This function returns the sum of two 32 bit integers.","salience":[0.55,0.31,0.20,0.38],"route":0,"cav":[0.11,0.15,0.19,0.08,0.17,0.07,0.18,0.13,0.20,0.09,0.14]}
{"norm_input":"let v = vec![1,2,3]; let s: i32 = v.iter().sum();","selected_mem_text":"Iterator adapters provide folds like sum for collections.","salience":[0.57,0.32,0.21,0.39],"route":0,"cav":[0.12,0.16,0.20,0.09,0.18,0.07,0.19,0.14,0.21,0.10,0.15]}
{"norm_input":"match x { 0 => \"zero\", _ => \"other\" }","selected_mem_text":"Pattern matching selects branches by value with a wildcard case.","salience":[0.56,0.33,0.20,0.37],"route":0,"cav":[0.11,0.15,0.19,0.08,0.17,0.07,0.18,0.13,0.20,0.09,0.14]}
{"norm_input":"let mut s = String::from(\"hi\"); s.push('!');","selected_mem_text":"Strings are growable and support push for char append.","salience":[0.54,0.30,0.19,0.36],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
{"norm_input":"#[derive(Debug, Clone)] struct Pt { x:i32, y:i32 }","selected_mem_text":"Derive adds common trait implementations automatically.","salience":[0.53,0.29,0.19,0.35],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
{"norm_input":"enum Route { Respond, Retrieve, Store, Defer }","selected_mem_text":"Enums model a set of discrete variants in Rust.","salience":[0.59,0.33,0.23,0.41],"route":0,"cav":[0.13,0.16,0.21,0.09,0.18,0.07,0.20,0.14,0.22,0.10,0.15]}
{"norm_input":"let m = vec![1,2,3].into_iter().map(|x| x*x).collect::<Vec<_>>();","selected_mem_text":"Map transforms items lazily and collect realizes the vector.","salience":[0.57,0.31,0.22,0.39],"route":0,"cav":[0.12,0.16,0.20,0.09,0.18,0.07,0.19,0.14,0.21,0.10,0.15]}
{"norm_input":"use std::fs; let txt = fs::read_to_string(\"data.txt\").unwrap();","selected_mem_text":"read_to_string loads a file into memory, returning a Result.","salience":[0.58,0.32,0.22,0.40],"route":0,"cav":[0.12,0.16,0.20,0.09,0.18,0.07,0.19,0.14,0.21,0.10,0.15]}
{"norm_input":"let now = std::time::SystemTime::now();","selected_mem_text":"SystemTime gives a monotonic-ish timestamp for events.","salience":[0.51,0.28,0.18,0.33],"route":0,"cav":[0.09,0.13,0.17,0.07,0.15,0.06,0.16,0.11,0.18,0.08,0.12]}
{"norm_input":"fn dot(a:&[f32], b:&[f32]) -> f32 { a.iter().zip(b).map(|(x,y)| x*y).sum() }","selected_mem_text":"Zip pairs slices and a fold computes the dot product.","salience":[0.60,0.34,0.24,0.42],"route":0,"cav":[0.13,0.17,0.22,0.10,0.19,0.08,0.21,0.15,0.23,0.11,0.16]}
{"norm_input":"let z = x.powi(2) + y.powi(2);","selected_mem_text":"Integer power on floats computes squared terms.","salience":[0.52,0.29,0.18,0.34],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
{"norm_input":"let mut map = std::collections::HashMap::new(); map.insert(\"k\",\"v\");","selected_mem_text":"HashMap stores key value pairs with hashing.","salience":[0.55,0.30,0.21,0.36],"route":0,"cav":[0.11,0.15,0.19,0.08,0.17,0.07,0.18,0.13,0.20,0.09,0.14]}
{"norm_input":"let s = format!(\"{} {}\", \"hello\", \"world\");","selected_mem_text":"format creates a new owned String from arguments.","salience":[0.54,0.30,0.20,0.36],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
{"norm_input":"#[inline] fn l2(x:f32,y:f32)->f32 { (x*x + y*y).sqrt() }","selected_mem_text":"A small inline helper computes Euclidean norm in 2D.","salience":[0.56,0.31,0.21,0.37],"route":0,"cav":[0.11,0.15,0.19,0.08,0.17,0.07,0.18,0.13,0.20,0.09,0.14]}
{"norm_input":"let norm = v.iter().map(|x| x*x).sum::<f32>().sqrt();","selected_mem_text":"Sum of squares followed by square root yields L2 norm.","salience":[0.57,0.32,0.22,0.39],"route":0,"cav":[0.12,0.16,0.20,0.09,0.18,0.07,0.19,0.14,0.21,0.10,0.15]}
{"norm_input":"let res: Vec<_> = it.filter(|x| *x > 0).take(3).collect();","selected_mem_text":"Filter keeps items by predicate and take limits the count.","salience":[0.53,0.29,0.20,0.35],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
{"norm_input":"#[test] fn smoke() { assert_eq!(2+2,4); }","selected_mem_text":"Unit tests verify small properties with assert macros.","salience":[0.50,0.27,0.18,0.32],"route":0,"cav":[0.09,0.13,0.17,0.07,0.15,0.06,0.16,0.11,0.18,0.08,0.12]}
{"norm_input":"let e = std::f32::consts::E; let pi = std::f32::consts::PI;","selected_mem_text":"Math constants are available under f32 consts.","salience":[0.51,0.28,0.18,0.33],"route":0,"cav":[0.09,0.13,0.17,0.07,0.15,0.06,0.16,0.11,0.18,0.08,0.12]}
{"norm_input":"if let Some(v) = maybe { println!(\"{}\", v); }","selected_mem_text":"if let unpacks matching enum variants concisely.","salience":[0.52,0.29,0.19,0.34],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
{"norm_input":"let clamp = x.max(0.0).min(1.0);","selected_mem_text":"Chaining min and max clamps a float into a range.","salience":[0.52,0.29,0.19,0.34],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
{"norm_input":"let avg = vals.iter().copied().sum::<f32>() / vals.len() as f32;","selected_mem_text":"Mean equals sum divided by count after casting length.","salience":[0.53,0.30,0.20,0.35],"route":0,"cav":[0.10,0.14,0.18,0.08,0.16,0.06,0.17,0.12,0.19,0.09,0.13]}
